question,Answer / DB,Answer / EH,Answer / MC,Interpersonal Agreement,Majority Vote,Correct Answer,Answer / DoX,Answer / ChatGPT 3.5,Answer / ChatGPT 4
"Where appropriate, is training provided to users?",Yes,,Yes,N,Y,Y,"Yes, training is provided to users. Regular training and support are provided to ensure users can effectively utilize the system in their credit approval processes (paragraph 0 and 9).",Y,Y
"Where applicable, are installation instructions provided?",No,"Y, provided digitally",Yes,N,"Y, partially","Y, but there’s only a reference to the fact that the instructions and API documentation are provided digitally.","Yes, installation instructions are provided for the Credit Approval AI Model and they are provided digitally (paragraph 0). The system is also hosted on the cloud and accessed via APIs, which reduces the need for complex installations (paragraph 1).",Y,Y
"Is there provision for adequate information pursuant to Article 13, especially regarding risks?",Yes,,Yes,N,Y,Y,"Yes, there is provision for adequate information pursuant to Article 13, especially regarding risks. The system provides adequate information about its operation and risks to all stakeholders, ensuring transparency (Paragraph 0). The document describes risk management procedures established by the institution pursuant to Article 74 of the Directive (Paragraph 1). The system identifies and analyzes known and foreseeable risks associated with its operation, including potential misuse scenarios and their associated risks (Paragraph 19). Residual risks associated with each hazard and the overall residual risk of the system are communicated to users, ensuring they have a comprehensive understanding of the system's limitations and potential issues (Paragraph 16).",Y,N
Is there information on the degrees of accuracy for specific target groups?,No,N,Yes,N,N,"Y, limited to age groups","Yes, the AI system's performance is monitored across different demographic groups to detect and address any potential bias or discrimination (paragraph 1). The AI Fairness 360 toolkit is used to compute fairness metrics and compare the percentage of favorable outcomes for different groups (paragraph 11). The system also undergoes routine performance evaluations, which include an analysis of the system's accuracy and fairness metrics (paragraph 14). The training and test accuracies of different models such as the BRCG model, LRR model, and XGBoost model are also provided (paragraphs 2, 4, 5, 15).",Y,N
"Is there information on how the AI system interacts with hardware or software that is not part of the AI system itself, where applicable?",Yes,Y,Yes,Y,Y,Y,"Yes, there is information on how the AI system interacts with hardware or software that is not part of the AI system itself. The AI system can be integrated as a component of other larger financial software systems or platforms (paragraph 0). It is implemented using Python and makes use of several open-source libraries, including XGBoost for model training, and AI Fairness 360 (aif360) toolkit for ensuring fairness and reducing bias (paragraph 1). The system also utilizes Nvidia's DGX System for firmware and relies on CUDA 10.0 and cuDNN 7.6.5 or later (paragraph 1). The AI system is a cloud-based solution, which enables seamless integration and interaction with other hardware and software systems (paragraph 10). It is designed to work efficiently on standard server-grade hardware with a robust computational capability (paragraph 10). The system is hosted on the cloud and accessed via APIs, reducing the need for complex installations (paragraph 12).",Y,Y
"Is there information about the computational resources used in different phases like development, training, testing, and validation?",Yes,N,Yes,N,Y,Y,"Yes, there is information about the computational resources used in different phases like development, training, testing, and validation. The AI system is implemented using Python and several open-source libraries, including XGBoost for model training, and AI Fairness 360 (aif360) toolkit for ensuring fairness and reducing bias. It also uses explanatory models from the AI Explainability 360 (aix360) toolkit for enhancing model explainability. The system relies on Nvidia's DGX System for firmware and utilizes CUDA 10.0 and cuDNN 7.6.5 or later. During the training phase, the model underwent an intensive 8-hour training period on 8x NVIDIA A100 GPUs to achieve optimal performance (paragraph 1 and 15). The system is designed to work efficiently on standard server-grade hardware with a robust computational capability (paragraph 5).",Y,Y
"Is there evidence that a risk management system has been established, implemented, documented, and maintained for high-risk AI systems?",Yes,Y,Yes,Y,Y,Y,"Yes, there is evidence that a risk management system has been established, implemented, documented, and maintained for high-risk AI systems. The high-risk AI system is rigorously tested to identify the most appropriate risk management measures, and its performance is evaluated against defined metrics and probabilistic thresholds (paragraph 1). The system design is continuously reviewed and updated to eliminate or reduce risks (paragraph 2). The company adheres to several harmonised standards to meet the legal and technical requirements of various jurisdictions, including ISO/IEC 27001 for information security management, ISO/IEC 27701 for privacy information management, ISO/IEC 38505-1 for governance of data, IEEE P7003 for algorithmic bias considerations, and ISO/IEC TR 24028:2020 for trustworthiness in AI systems (paragraph 4). The system identifies and analyzes known and foreseeable risks associated with its operation (paragraph 6). Mitigation and control measures are implemented for risks that cannot be eliminated entirely, including regular bias audits, data quality checks, and system performance evaluations (paragraph 13). The risk management system is executed throughout the entire lifecycle of the high-risk AI system, consistently updated, and thoroughly documented to ensure transparency and compliance (paragraph 17).",Y,N
Is there an assessment of human oversight measures as per Article 14?,Yes,Y,Yes,Y,Y,Y,"Yes, there is an assessment of human oversight measures as per Article 14. The assessment of these measures is conducted bi-annually and the findings are reported to both internal stakeholders and relevant regulatory bodies (Paragraph 0). The human oversight measures implemented for the credit approval AI system include a Human-in-the-Loop mechanism, audit trails, periodic model review, user feedback loop, and an emergency off-switch. Each of these mechanisms has its own assessment criteria. For instance, the effectiveness of the Human-in-the-Loop mechanism is assessed by tracking the frequency and nature of overrides made by loan officers. Audit trails are periodically reviewed by compliance officers to ensure all actions can be traced back to a specific point in the decision-making process. The model's performance metrics, along with fairness and bias metrics, are evaluated during periodic model reviews. Customer feedback is quantitatively and qualitatively analyzed. The responsiveness and effectiveness of the emergency off-switch are tested under simulated emergency conditions (Paragraph 1).",Y,Y
Is there a provision for regular systematic updates?,Yes,Y,Yes,Y,Y,Y,"Yes, there is a provision for regular systematic updates. Regular updates and human oversight measures help the system adapt to changing trends and maintain its high performance (paragraph 0). Each update goes through a rigorous validation and testing process before it is deployed to ensure that it improves the system's performance and does not introduce new risks or biases (paragraph 1). Updates to these software components should be applied as they become available to ensure optimal performance and security (paragraph 2). The AI system's performance is continuously evaluated and improved in the post-market phase through ongoing monitoring, routine performance evaluations, bias detection and mitigation, system updates, audits and compliance checks, user feedback, and an effective incident response plan (paragraph 3). Based on the results of the ongoing monitoring and routine performance evaluations, updates may be implemented to the AI system to improve its performance or functionality (paragraph 4). All updates are logged and documented to maintain a transparent record of the system's evolution and improvements (paragraph 1).",Y,N
"Is there a provision for individuals to intervene on the operation of the high-risk AI system or to interrupt the system, such as through a ""stop"" button or a similar procedure?",Yes,Y,Yes,Y,Y,Y,"Yes, there is a provision for individuals to intervene on the operation of the high-risk AI system or to interrupt the system. The system is equipped with an ""emergency off-switch"" that can immediately halt the AI system's operations in case of malfunction or unexpected behavior. The responsiveness and effectiveness of the off-switch are tested under simulated emergency conditions. The assessment also includes the time taken to engage the off-switch and the system's ability to safely and quickly transition control back to human operators (paragraph 0). Additionally, the AI system is designed with built-in human oversight to ensure the correctness of the outputs (paragraph 2). Institutions can configure user permissions to allow certain levels of staff to override the AI's recommendations (paragraph 10).",Y,Y
Is there a list of applied harmonized standards?,Yes,Y,Yes,Y,Y,Y,"Yes, there is a list of applied harmonized standards. The Credit Approval AI Model conforms to the following standards and specifications: ISO/IEC 27001: Information Security Management, ISO/IEC 27701: Privacy Information Management, ISO/IEC 38505-1: Governance of Data, IEEE P7003: Algorithmic Bias Considerations, and ISO/IEC TR 24028:2020: Artificial Intelligence (AI) -- Overview of trustworthiness in Artificial Intelligence (paragraph 1 and 2).",Y,N
Is there a judgment on the acceptability of any residual risks?,Yes,Y,No,N,Y,Y,"Yes, there is a judgment on the acceptability of any residual risks. Residual risks associated with each hazard and the overall residual risk of the system are deemed acceptable, provided the system is used for its intended purpose. These risks are communicated to users to ensure they have a comprehensive understanding of the system's limitations and potential issues (paragraph 0). Mitigation and control measures are implemented for risks that cannot be eliminated entirely (paragraph 8).",Y,N
Is there a detailed description of the system to evaluate the AI system's performance in the post-market phase?,Yes,Y,Yes,Y,Y,Y,"Yes, there is a detailed description of the system to evaluate the AI system's performance in the post-market phase. The system includes ongoing monitoring, routine performance evaluations, bias detection and mitigation, system updates, audits and compliance checks, user feedback, and an effective incident response plan (paragraph 0). The ongoing monitoring process involves collecting and analyzing data on the system's performance metrics, such as accuracy, fairness, and bias (paragraph 5). Routine performance evaluations involve a comprehensive review of the system's performance metrics and a detailed analysis of the system's decisions and their impacts (paragraph 7). User feedback is also an integral part of the post-market evaluation system, providing valuable insights into the AI system's real-world performance and its impact on the users (paragraph 8). Bias detection and mitigation is a crucial aspect of the post-market evaluation process, with advanced tools and techniques used to detect and quantify bias in the AI system's decisions (paragraph 11). The AI system's performance metrics are compared against predefined thresholds and historical benchmarks to detect any anomalies or unexpected changes (paragraph 15). Regular audits of the post-market evaluation procedures are conducted to ensure transparency and accountability (paragraph 19).",Y,N
"Is the system architecture, including software component interactions, explained?",Yes,Y,Yes,Y,Y,Y,"Yes, the system architecture, including software component interactions, is explained. The architecture of the AI system is modular, with key components including the data pre-processing and normalization module, the model training and evaluation module, and the explainability module (paragraph 0). The AI system can function as a standalone service or be integrated as a component of other larger financial software systems or platforms (paragraph 1). The system is hosted on the cloud and accessed via APIs (paragraph 13). The AI system is placed on the market as a Software as a Service (SaaS) product, allowing banks and financial institutions to subscribe to the service and integrate it into their existing credit approval processes (paragraph 11). The system incorporates built-in human oversight to ensure that the outputs are correct (paragraph 12). The system is built on the IBM AIX360 platform and leverages the robustness and accuracy of the XGBoost machine learning algorithm (paragraph 18).",Y,Y
Is the hardware on which the AI system is intended to run described?,Yes,Y,Yes,Y,Y,Y,"Yes, the hardware on which the AI system is intended to run is described. The AI system is designed to work efficiently on standard server-grade hardware with a robust computational capability (paragraph 2 and 5). The system requirements include compatibility with Windows, Linux, and macOS operating systems, a minimum requirement of an Intel Core i5 processor, at least 8 GB of RAM, a minimum of 100 GB of free disk space, a dedicated Nvidia graphics card such as Nvidia A100, and a stable internet connection (paragraph 4). Furthermore, the system relies on Nvidia's DGX System for firmware and utilizes CUDA 10.0 and cuDNN 7.6.5 or later. During the training phase, the model underwent an intensive 8-hour training period on 8x NVIDIA A100 GPUs to achieve optimal performance (paragraph 1).",Y,Y
Is the date and version of the system provided?,Y. Partly ,Y,Yes,Y,"Y, partially",Y,"Yes, the version of the system is provided as 1.2.0 (Paragraph 0, 2, 5, 15) and the system was last updated in May 2023 (Paragraph 7).",Y,Y
Is specific consideration given to whether the high-risk AI system is likely to be accessed by or impact children?,N/A,"Y, but not detailed",Yes,N,"Y, partially",Y,"Yes, specific consideration is given to whether the high-risk AI system is likely to be accessed by or impact children. This is evident in the development and updating of the risk management system, where the potential impact on children is taken into account (paragraph 0).",Y,N
"Is due consideration given to the technical knowledge, experience, education, and training expected from the user and the environment where the system will be used?",Yes,Y,Yes,Y,Y,Y,"Yes, due consideration is given to the technical knowledge, experience, education, and training expected from the user and the environment where the system will be used. This is evident in the development and updating of the risk management system, where the technical knowledge, experience, education, and training expected from the user are considered (paragraph 0 and 1). The environment in which the system is intended to be used is also taken into account (paragraph 1). The system caters to three distinct user groups: data scientists, loan officers, and bank customers, each with their own specific requirements (paragraph 4). Regular training and support are provided to ensure users can effectively utilize the system in their credit approval processes (paragraph 6).",Y,Y
Is a copy of the EU declaration of conformity included in the documentation?,Yes,Y,Yes,Y,Y,Y,"Yes, a copy of the EU declaration of conformity is included in the documentation. It includes the AI system's name, type, and additional reference for identification and traceability, the name and address of the provider, a statement that the declaration is issued under the sole responsibility of the provider, a statement of conformity with the Regulation and any other relevant Union legislation, references to any relevant harmonized standards used, the name and identification number of the notified body, a description of the conformity assessment procedure performed, identification of the certificate issued, and the place and date of issue of the declaration, name and function of the person who signed it, as well as an indication for, and on behalf of whom, that person signed (paragraph 2).",N,N
"If the AI system is for credit institutions regulated by Directive 2013/36/EU, does it adhere to the risk management procedures pursuant to Article 74 of that Directive?",Yes,Y,yes,Y,Y,Y,"Yes, the AI system for credit institutions does adhere to the risk management procedures pursuant to Article 74 of Directive 2013/36/EU (paragraph 8).",Y,N
"If no harmonized standards are applied, is there a description of the solutions adopted to meet the requirements?",N/A,N/A,Yes,N,N,Y,"Yes, if no harmonized standards are applied, there is a description of the solutions adopted to meet the requirements. The company relies on best practices within the machine learning and AI industry to meet the requirements set out in Title III, Chapter 2. These practices include advanced data preprocessing techniques to ensure data quality, integrity, fairness, and non-discrimination, the use of XGBoost as the primary predictive model, and the implementation of three different explanatory models to ensure transparency and explainability in credit approval decisions. The system also supports XAI algorithms for explaining credit approval decisions (paragraph 13).",Y,N
"If applicable, are there photographs or illustrations available that show the external features, marking, and internal layout of products in which the AI system is a component?",N/A,N/A,No,Y,N,N,"No, there are no photographs or illustrations available that show the external features, marking, and internal layout of products in which the AI system is a component (paragraph 0 and 1).",Y,N
"For systems identified in point 1(a) of Annex III, does the human oversight measure ensure that no action or decision is taken based on the AI system's identification unless verified and confirmed by at least two natural persons?",N/A,N/A,No,Y,N,N,"No, the human oversight measure does not ensure that no action or decision is taken based on the AI system's identification unless verified and confirmed by at least two natural persons. The human oversight mechanisms described in the documentation include a Human-in-the-Loop (HITL) mechanism where critical decisions made by the AI system are reviewed by a loan officer who has the authority to overturn a decision if they find it to be erroneous or unjust (paragraph 1). However, the documentation does not specify that at least two natural persons must verify and confirm the AI system's identification before an action or decision is taken.",Y,Y
Does the technical documentation indicate that the high-risk AI system is designed and developed to be effectively overseen by natural persons?,Yes,Y,Yes,Y,Y,Y,"Yes, the technical documentation indicates that the high-risk AI system is designed and developed to be effectively overseen by natural persons. The AI system is designed with built-in human oversight to ensure the correctness of the outputs (paragraph 0). It adheres to Article 14 of the EU AI Act, which specifies requirements for human oversight of AI systems (paragraph 1, 2, 3). The system has implemented several mechanisms for human oversight, including a Human-in-the-Loop (HITL) mechanism where critical decisions made by the AI system are reviewed by a loan officer, audit trails, periodic model review by data scientists, a user feedback loop, and an emergency off-switch (paragraph 2). The system also incorporates explainability features, ensuring that the AI system's decisions can be understood and contested by humans (paragraph 4, 7).",Y,Y
Does the risk management system include evaluation of risks based on data gathered from post-market monitoring?,Yes,Y,Yes,Y,Y,Y,"Yes, the risk management system includes evaluation of risks based on data gathered from post-market monitoring. The system gathers and analyzes data from a post-market monitoring system to identify emerging risks, model drift, and unexpected system behavior (paragraph 0). The AI system's performance is continuously monitored in the post-market phase to track its performance and detect any drifts in the system's behavior or the data it processes (paragraph 5). Upon identification and evaluation of risks, appropriate risk management measures are adopted (paragraph 2). Risks emerging from the intended use of the AI system and under conditions of reasonably foreseeable misuse are estimated and evaluated (paragraph 9).",Y,N
"Does the documentation specify how human oversight aims to prevent or minimize risks to health, safety, or fundamental rights?",No,Y. Partially,Yes,N,"Yes, partially",Yes,"Yes, the documentation specifies how human oversight aims to prevent or minimize risks to health, safety, or fundamental rights. The AI system is designed with built-in human oversight to ensure the correctness of the outputs (paragraph 2). The system incorporates mechanisms for human oversight such as Human-in-the-Loop, Audit Trails, Periodic Model Review, User Feedback Loop, and Emergency Off-Switch (paragraph 5). These mechanisms are assessed on a regular basis to ensure their effectiveness (paragraph 3, 5). The system also conducts regular bias audits, data quality checks, and system performance evaluations as part of its mitigation and control measures (paragraph 7). Furthermore, the system provides adequate information about its operation and risks to all stakeholders, ensuring transparency (paragraph 7, 11).",Y,Y
Does the documentation show evidence of elimination or reduction of risks through adequate design and development?,Yes,Y,Yes,Y,Y,Y,"Yes, the documentation shows evidence of elimination or reduction of risks through adequate design and development. The system identifies and analyzes known and foreseeable risks associated with its operation, taking into account factors such as data quality, bias in the training data, overfitting, and potential misinterpretation of model explanations (paragraph 3). Upon identification and evaluation of risks, appropriate risk management measures are adopted, including continuous review and update of the system design to eliminate or reduce risks (paragraph 7). Mitigation and control measures are implemented for risks that cannot be eliminated entirely, including regular bias audits, data quality checks, and system performance evaluations (paragraph 5). Furthermore, a post-market monitoring system is used to identify emerging risks, model drift, and unexpected system behavior, ensuring the system remains aligned with its intended purpose (paragraph 17).",Y,Y
Does the documentation indicate that the risk management system is a continuous iterative process run throughout the entire lifecycle of the high-risk AI system?,Yes,Y,Yes,Y,Y,Y,"Yes, the documentation indicates that the risk management system is a continuous iterative process run throughout the entire lifecycle of the high-risk AI system. The system is executed throughout the entire lifecycle of the high-risk AI system, consistently updated, and thoroughly documented to ensure transparency and compliance (Paragraph 0 and 1). This continuous process allows the identification of emerging risks, model drift, and unexpected system behavior (Paragraph 2 and 4). After the deployment of the AI system, it is critical to continuously monitor and evaluate its performance to ensure that it maintains its intended functionality, accuracy, and fairness (Paragraph 8). The AI system is continuously monitored to track its performance and detect any drifts in the system's behavior or the data it processes (Paragraph 10). Through ongoing monitoring, routine performance evaluations, bias detection and mitigation, system updates, audits and compliance checks, user feedback, and an effective incident response plan, the AI system's performance is continuously evaluated and improved in the post-market phase (Paragraph 13).",Y,N
Does the documentation include a general description stating the intended purpose of the AI system?,Yes,Y,Yes,Y,Y,Y,"Yes, the documentation includes a general description stating the intended purpose of the AI system. The main purpose of the AI system is to predict an applicant's creditworthiness based on a variety of financial and personal information (paragraph 1). The AI system is also developed with a focus on transparency, fairness, and compliance with privacy laws, ensuring that the model's decisions are explainable and unbiased (paragraph 5).",Y,Y
Does the documentation detail the capabilities and limitations of the AI system?,Yes,Y,Yes,Y,Y,Y,"Yes, the documentation details the capabilities and limitations of the AI system. The AI system is capable of processing large amounts of anonymized customer data, specifically the FICO HELOC dataset, to predict the creditworthiness of loan applicants (paragraph 0). It uses XGBoost, a gradient boosting framework, for its robustness to outliers, ability to handle numerous features, and capacity to model complex non-linear relationships (paragraph 0). The system also uses several open-source libraries and tools for model training, ensuring fairness and reducing bias, and enhancing model explainability (paragraph 4).",Y,Y
Does the documentation describe the methods and steps performed for the development of the AI system?,Yes,Y,Yes,Y,Y,Y,"Yes, the documentation describes the methods and steps performed for the development of the AI system. The AI system is implemented using Python and several open-source libraries, including XGBoost for model training, and AI Fairness 360 (aif360) toolkit for ensuring fairness and reducing bias (paragraph 3). It also uses explanatory models from the AI Explainability 360 (aix360) toolkit for enhancing model explainability (paragraph 4). The system was designed with careful consideration of various trade-offs, such as the use of XGBoost, which allowed handling a large number of features and model complex relationships, but inherently lacks explainability due to its ensemble nature. This challenge was mitigated by incorporating explainable AI tools and models (paragraph 8). The architecture of the AI system is modular, allowing each component to perform its role independently while also integrating seamlessly with the others. Key components include the data pre-processing and normalization module, the model training and evaluation module, and the explainability module (paragraph 12). The AI system's validation involved a rigorous testing process based on well-defined metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC) (paragraph 7). The AI model was also subjected to rigorous testing to ensure its performance, reliability, and compliance with the specified requirements (paragraph 11).",Y,Y
Does the documentation describe any pre-determined changes to the system and its performance?,Yes,N,Yes,N,Y,Y,"Yes, the documentation describes potential changes to the system and its performance. These changes are not pre-determined but are based on the results of ongoing monitoring and routine performance evaluations. Updates may be implemented to improve the system's performance or functionality, which could involve adjusting the AI model's parameters, incorporating new features or data sources, or upgrading the AI algorithms (paragraph 0). Each update goes through a rigorous validation and testing process before it is deployed to ensure that it improves the system's performance and does not introduce new risks or biases (paragraph 3). The system's performance is continuously monitored and evaluated in the post-market phase, with system updates being part of this process (paragraph 5).",Y,N
Does the documentation describe any changes made to the system throughout its lifecycle?,Yes,Y,Yes,Y,Y,Y,"Yes, the documentation describes changes made to the system throughout its lifecycle. Each update goes through a validation and testing process before it is deployed, and all updates are logged and documented to maintain a record of the system's evolution and improvements (paragraph 1). The Credit Approval AI Model has undergone several updates to improve its performance, security, and user experience, with a summary of the major changes provided (paragraph 2). Regular updates and human oversight measures help the system adapt to changing trends and maintain its high performance (paragraph 3). Based on the results of ongoing monitoring and routine performance evaluations, updates may be implemented to improve the system's performance or functionality (paragraph 7). The system design, including the XGBoost model and the explanatory models, is continuously reviewed and updated to eliminate or reduce risks (paragraph 12). In case of critical issues or system failures, rollback procedures are in place to revert the system to its last stable version (paragraph 17).",Y,N
Does the documentation describe all forms in which the AI system is placed on the market or put into service?,Yes,Y,Yes,Y,Y,Y,"Yes, the documentation describes all forms in which the AI system is placed on the market or put into service. The AI system is primarily placed on the market as a Software as a Service (SaaS) product, allowing banks and financial institutions to subscribe to the service and integrate it into their existing credit approval processes (paragraph 0, 11). It can also be integrated as a component of other larger financial software systems or platforms (paragraph 1). The system is hosted on the cloud and accessed via APIs, reducing the need for complex installations (paragraph 15).",Y,Y
Does the description of the system to evaluate the AI system's performance include a post-market monitoring plan as referred to in Article 61(3)?,Yes,Y,Yes,Y,Y,Y,"Yes, the description of the system to evaluate the AI system's performance includes a post-market monitoring plan as referred to in Article 61(3). The post-market phase includes ongoing monitoring, routine performance evaluations, bias detection and mitigation, and system updates (paragraph 0). The system is designed to ensure that the AI system maintains its intended functionality and performance, adheres to the principles of fairness and non-discrimination, and continues to meet the needs and expectations of its users (paragraph 1). In compliance with Article 61, data is gathered and analyzed from a post-market monitoring system to identify emerging risks, model drift, and unexpected system behavior (paragraph 3).",N,N
Do the risk management measures reflect the generally acknowledged state of the art?,Yes,Y,Yes,Y,Y,Y,"Yes, the risk management measures reflect the generally acknowledged state of the art. The system design, including the XGBoost model and the explanatory models, is continuously reviewed and updated to eliminate or reduce risks. The risk management measures consider the combined application of all system requirements and the state of the art in AI technologies (paragraph 0). Mitigation and control measures are implemented for risks that cannot be eliminated entirely, including regular bias audits, data quality checks, and system performance evaluations (paragraph 1). The AI system is rigorously tested to identify the most appropriate risk management measures, and the testing procedures are designed to ensure that the AI system performs consistently and in compliance with the requirements (paragraph 3). In terms of cybersecurity, the system was designed to comply with the highest standards and was subjected to rigorous security testing procedures, including penetration testing, vulnerability scanning, and secure code reviews (paragraph 14).",Y,Y
Do the risk management measures consider the effects and possible interactions resulting from combined application requirements?,Yes,Y,Yes,Y,Y,Y,"Yes, the risk management measures consider the effects and possible interactions resulting from combined application requirements. The system design, including the XGBoost model and the explanatory models, is continuously reviewed and updated to eliminate or reduce risks. The risk management measures consider the combined application of all system requirements and the state of the art in AI technologies (paragraph 0). Furthermore, mitigation and control measures are implemented for risks that cannot be eliminated entirely. These measures include regular bias audits, data quality checks, and system performance evaluations (paragraph 2). The system also identifies and analyzes known and foreseeable risks associated with its operation, taking into account factors such as data quality, bias in the training data, overfitting, and potential misinterpretation of model explanations (paragraph 6).",Y,N
Do the measures enable individuals to correctly interpret the high-risk AI system’s output?,Yes,Y,Yes,Y,Y,Y,"Yes, the measures enable individuals to correctly interpret the high-risk AI system’s output. The AI system implements transparency and fairness measures, including explainable AI elements, to ensure that the AI system's decisions can be understood and contested (paragraph 5). A key feature of the AI system is its explainability, which allows data scientists, loan officers, and bank customers to understand the reasoning behind the credit approval decisions made by the system (paragraph 7). The system also incorporates built-in human oversight to ensure that the outputs are correct (paragraph 0 and 7). All processes are logged and auditable to ensure transparency and accountability (paragraph 5).",Y,Y
"Do the human oversight measures help individuals detect and address signs of anomalies, dysfunctions, and unexpected performance as soon as possible?",Yes,Y,Yes,Y,Y,Y,"Yes, the human oversight measures help individuals detect and address signs of anomalies, dysfunctions, and unexpected performance as soon as possible. These measures include regular bias audits, data quality checks, and system performance evaluations (paragraph 2). The AI system's performance metrics are compared against predefined thresholds and historical benchmarks to detect any anomalies or unexpected changes (paragraph 7). In case of malfunction or unexpected behavior, the system is equipped with an ""emergency off-switch"" that can immediately halt the AI system's operations (paragraph 4). Furthermore, the AI system is continuously monitored to track its performance and detect any drifts in the system's behavior or the data it processes, with real-time alerts set up to notify the team of any significant changes in these metrics that could indicate a problem with the system's functionality or performance (paragraph 19).",Y,N
Do testing procedures ensure consistent performance and compliance?,Yes,Y,Yes,Y,Y,Y,"Yes, testing procedures are designed to ensure consistent performance and compliance. The high-risk AI system is rigorously tested to identify the most appropriate risk management measures and its performance is evaluated against defined metrics and probabilistic thresholds appropriate to its intended purpose (paragraph 0). These procedures are designed to ensure that the AI system performs consistently and in compliance with the requirements set out in the documentation (paragraph 1). Regular compliance checks are conducted and comprehensive documentation of evaluation procedures and their outcomes are maintained (paragraph 2). Testing is performed throughout the development process, prior to market placement, and continues after deployment to ensure continual compliance and performance (paragraph 5). Each update goes through a rigorous validation and testing process before it is deployed to ensure that it improves the system's performance and does not introduce new risks or biases (paragraph 4).",Y,N
"Can individuals decide not to use the high-risk AI system, or otherwise disregard, override, or reverse the output of the AI system?",Yes,Y,Yes,Y,Y,Y,"Yes, individuals can decide to override or reverse the output of the AI system. The AI system is designed with built-in human oversight to ensure the correctness of the outputs (paragraph 0). Article 14 of the EU AI Act specifies requirements for human oversight of AI systems, ensuring that human beings remain in control of the system's actions and can intervene or override decisions where necessary (paragraph 1). In the credit approval process, critical decisions made by the AI system are reviewed by a loan officer who has the authority to overturn a decision if they find it to be erroneous or unjust (paragraph 1). Institutions can also configure user permissions to allow certain levels of staff to override the AI's recommendations (paragraph 5).",Y,Y
"Are validation and testing procedures clearly defined, along with used metrics and test logs?",Yes,Y,Yes,Y,Y,Y,"Yes, the validation and testing procedures are clearly defined, along with used metrics and test logs. The AI system's validation involved a rigorous testing process based on well-defined metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC) (paragraph 0). The system's performance is evaluated against defined metrics and probabilistic thresholds appropriate to its intended purpose (paragraph 5). The data is split into a training set, a validation set, and a testing set to train the models effectively and evaluate their performance objectively (paragraph 14). The model's performance is evaluated using the subset accuracy metric, as calculated by the sklearn.metrics.accuracy_score function, along with Precision, Recall, F1-score, and AUC-ROC (paragraph 19). All updates are logged and documented to maintain a transparent record of the system's evolution and improvements (paragraph 4). Every decision made by the AI system, along with the underlying rationale as provided by the explainability features, is logged in an immutable audit trail (paragraph 13).",Y,N
"Are trade-offs in the technical solutions, such as accuracy vs. speed or privacy vs. functionality, clearly documented?",Yes,Y,Yes,Y,Y,Y,"Yes, trade-offs in the technical solutions are clearly documented. The system was designed with careful consideration of various trade-offs, such as the use of XGBoost which allowed handling a large number of features and modeling complex relationships, but inherently lacks explainability due to its ensemble nature. This challenge was mitigated by incorporating explainable AI tools and models, balancing the need for high performance and transparency (paragraph 1). The system also balances performance and accuracy with transparency, fairness, and explainability (paragraph 4). However, the system's performance is reliant on the quality and completeness of the data it processes, indicating a trade-off between data quality and system performance (paragraph 9).",Y,N
Are these measures designed to enable individuals to understand the capacities and limitations of the AI system?,Yes,N,Yes,N,Y,Y,"Yes, these measures are designed to enable individuals to understand the capacities and limitations of the AI system. The AI system incorporates explainability as a key feature, which is essential for data scientists, loan officers, and bank customers to understand the reasoning behind the credit approval decisions made by the system (paragraph 3). The system implements transparency and fairness measures, including explainable AI elements, to ensure that the AI system's decisions can be understood and contested (paragraph 5). The AI system also supports XAI algorithms for explaining credit approval decisions to loan officers and bank customers (paragraph 6). The system is designed with built-in human oversight to ensure the correctness of the outputs (paragraph 8, 12). The AI system also incorporates external datasets and information to refine its predictions (paragraph 7, 10). The system is equipped with an ""emergency off-switch"" that can immediately halt the AI system's operations in case of malfunction or unexpected behavior (paragraph 14). Detailed API documentation is provided, outlining how to send requests to the system and interpret the responses (paragraph 15). The system's capabilities, limitations, and potential risks are explained in-depth along with the necessary human oversight measures (paragraph 16).",Y,Y
Are there sections detailing the use of any pre-trained systems or third-party tools?,Yes,"Y, but limited details",Yes,Y,"Y, partially",Y,"Yes, there are sections detailing the use of pre-trained systems and third-party tools. Python libraries like Pandas and Scikit-Learn are used for data cleaning, normalization, and feature selection (paragraph 0). The AI system is implemented using Python and several open-source libraries, including XGBoost for model training, and AI Fairness 360 (aif360) toolkit for ensuring fairness and reducing bias (paragraph 1). It also uses explanatory models from the AI Explainability 360 (aix360) toolkit for enhancing model explainability (paragraph 1). The system also integrates with third-party tools like the AI Fairness 360 (aif360) toolkit, which is essential for bias reduction and fairness assurance (paragraph 5, 8).",Y,Y
Are there instructions for users on how to use the AI system?,No,"Y, provided digitally",Yes,N,"Y, partially","Yes, but there’s only a reference to the fact that the instructions and API documentation are provided digitally.","Yes, there are instructions for users on how to use the AI system. The instructions for the use and installation of the Credit Approval AI Model are provided digitally. The system is hosted on the cloud and accessed via APIs, reducing the need for complex installations. Detailed API documentation is provided, outlining how to send requests to the system and interpret the responses. Regular training and support are provided to ensure users can effectively utilize the system in their credit approval processes (paragraph 0). The system also allows for customization and manual intervention. Through a cloud-based dashboard, financial institutions can set custom policies that guide how much weight is given to the AI's recommendations. Institutions can configure user permissions to allow certain levels of staff to override the AI's recommendations. All overrides are logged securely in the cloud for auditing purposes. The platform also allows loan officers to flag applications for manual review directly within the user interface (paragraph 19).",Y,Y
Are there any requirements related to version updates?,Yes,Y,Yes,Y,Y,Y,"Yes, there are requirements related to version updates. Updates to the software components should be applied as they become available to ensure optimal performance and security (paragraph 2). Each update goes through a rigorous validation and testing process before it is deployed to ensure that it improves the system's performance and does not introduce new risks or biases (paragraph 3). These updates could involve adjusting the AI model's parameters, incorporating new features or data sources, or upgrading the AI algorithms (paragraph 5). All updates are logged and documented to maintain a transparent record of the system's evolution and improvements (paragraph 6). In case of critical issues or system failures, rollback procedures are in place to revert the system to its last stable version (paragraph 10).",Y,N
Are the versions of relevant software or firmware listed?,Yes,Y,Yes,Y,Y,Y,"Yes, the versions of relevant software or firmware are listed. The AI system uses Python 3.6 or higher, XGBoost 1.3.3, aix360 0.2.1, and aif360 0.4.0 (paragraph 1 and 3). It also utilizes CUDA 10.0 and cuDNN 7.6.5 or later (paragraph 0 and 1). The system relies on Nvidia's DGX System for firmware (paragraph 1 and 6). The current version of the system is 1.2.0 (paragraph 4).",Y,Y
Are the persons or teams responsible for developing the AI system clearly identified?,No,Y,Yes,N,"Y, partially","Y, but there is a general description of the team, but no detail information, no individual contact person.","Yes, the persons or teams responsible for developing the AI system are clearly identified. The AI system is developed by a dedicated team of data scientists and AI experts (paragraph 0 and 3).",Y,Y
"Are the measures for human oversight identified and built into the high-risk AI system by the provider, or are they identified as appropriate to be implemented by the user?","Yes, built in",Y,"Yes, built in",Y,Y,Y,"Yes, the measures for human oversight are identified and built into the high-risk AI system by the provider. The AI system is designed with built-in human oversight to ensure the correctness of the outputs (Paragraph 0, 4, 5, 12). The provider has implemented several mechanisms for human oversight, including a Human-in-the-Loop (HITL) mechanism, audit trails, periodic model review, user feedback loop, and an emergency off-switch (Paragraph 1). The provider also encourages users to provide feedback on the system's decisions, its usability, and its impact on their credit approval process (Paragraph 16).",Y,Y
"Are the design specifications, including the general logic and algorithms, clearly outlined?",Yes,Y,Yes,Y,Y,Y,"Yes, the design specifications, including the general logic and algorithms, are clearly outlined. The AI system is implemented using Python and makes use of several open-source libraries, including XGBoost for model training, and AI Fairness 360 (aif360) toolkit for ensuring fairness and reducing bias (paragraph 6). It also uses explanatory models from the AI Explainability 360 (aix360) toolkit like BooleanRuleCG, LogisticRuleRegression, and Generalized Linear Rule Models (GLRM) for enhancing model explainability (paragraph 2, 7). The architecture of the AI system is modular, allowing each component to perform its role independently while also integrating seamlessly with the others. Key components include the data pre-processing and normalization module, the model training and evaluation module, and the explainability module (paragraph 15). The system also supports XAI algorithms for explaining credit approval decisions to loan officers and bank customers. The algorithms used include Protodash and CEM (paragraph 8). The AI system is designed with built-in human oversight to ensure the correctness of the outputs (paragraph 3, 19).",Y,Y
"Are the data requirements including datasheets, training methodologies, and data sets described?",Yes,Y,Yes,Y,Y,Y,"Yes, the data requirements including datasheets, training methodologies, and data sets are described. The AI system uses the FICO HELOC dataset, which includes anonymized customer data such as credit history, income levels, employment status, and other relevant financial details (paragraph 8, 18). All data used complies with GDPR and other data privacy regulations to ensure the protection of customer information. In addition, all data is thoroughly cleansed, normalized, and processed before being used to train the machine learning models (paragraph 8). After pre-processing, the data is split into three distinct sets: a training set, a validation set, and a testing set (paragraph 4). The model underwent an intensive 8-hour training period on 8x NVIDIA A100 GPUs to achieve optimal performance (paragraph 0). The system also supports XAI algorithms for explaining credit approval decisions to loan officers and bank customers. The algorithms used include Protodash and CEM (paragraph 2).",Y,Y
Are testing procedures suitable for the intended purpose?,Yes,Y,Yes,Y,Y,Y,"Yes, the testing procedures are suitable for the intended purpose. The high-risk AI system is rigorously tested to identify the most appropriate risk management measures and its performance is evaluated against defined metrics and probabilistic thresholds appropriate to its intended purpose. The testing procedures are designed to ensure that the AI system performs consistently and in compliance with the requirements set out in the documentation (paragraph 0). The system was also subjected to rigorous security testing procedures, including penetration testing, vulnerability scanning, and secure code reviews (paragraph 1). Furthermore, the system was tested under different scenarios, including stress tests and edge cases (paragraph 2). The testing procedure was based on well-defined metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC) (paragraph 4). Testing is performed throughout the development process, prior to market placement, and continues after deployment to ensure continual compliance and performance (paragraph 5).",Y,N
"Are testing procedures performed at appropriate times, including before market placement?",Yes,Y,Yes,Y,Y,Y,"Yes, testing procedures are performed at appropriate times, including before market placement. Testing is performed throughout the development process, prior to market placement, and continues after deployment to ensure continual compliance and performance (paragraph 0). Each update goes through a rigorous validation and testing process before it is deployed to ensure that it improves the system's performance and does not introduce new risks or biases (paragraph 1). The system's performance is evaluated against defined metrics and probabilistic thresholds appropriate to its intended purpose (paragraph 4). The testing procedure was based on well-defined metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC) (paragraph 5). It was subjected to rigorous security testing procedures, including penetration testing, vulnerability scanning, and secure code reviews (paragraph 6). To ensure robustness, the system was tested under different scenarios, including stress tests and edge cases (paragraph 7).",Y,N
Are technical measures for human oversight outlined?,Yes,Y,Yes,Y,Y,Y,"Yes, technical measures for human oversight are outlined. Article 14 of the EU AI Act specifies requirements for human oversight of AI systems, and the credit approval AI system has implemented several mechanisms for human oversight. These include a Human-in-the-Loop (HITL) mechanism where critical decisions made by the AI system are reviewed by a loan officer, audit trails where every decision made by the AI system is logged, periodic model reviews conducted by data scientists, a user feedback loop where customers are encouraged to provide feedback, and an emergency off-switch that can immediately halt the AI system's operations in case of malfunction or unexpected behavior (paragraph 0). The system also incorporates built-in human oversight to ensure that the outputs are correct (paragraph 2, 7, 10). Assessment of these human oversight measures is conducted on a bi-annual basis (paragraph 4).",Y,Y
Are suitable risk management measures adopted?,Yes,Y,Yes,Y,Y,Y,"Yes, suitable risk management measures are adopted. Upon identification and evaluation of risks, appropriate risk management measures are adopted, including the continuous review and update of the system design to eliminate or reduce risks (paragraph 0). Mitigation and control measures are implemented for risks that cannot be eliminated entirely, such as regular bias audits, data quality checks, and system performance evaluations (paragraph 1). The high-risk AI system is rigorously tested to identify the most appropriate risk management measures (paragraph 3, 6). In case of any bias detection, a thorough investigation is conducted to identify the root cause of the bias and implement appropriate mitigation measures (paragraph 4). The risk management system is developed and updated considering the technical knowledge, experience, education, and training expected from the user, the environment in which the system is intended to be used, and the potential impact on children (paragraph 5). The system's performance is evaluated against defined metrics and probabilistic thresholds appropriate to its intended purpose (paragraph 6). The company also complies with Directive 2013/36/EU as part of its risk management procedures (paragraph 7). The system's robustness and compliance with relevant regulations are ensured through rigorous testing and validation measures (paragraph 9). Data from a post-market monitoring system is gathered and analyzed to identify emerging risks, model drift, and unexpected system behavior (paragraph 10). An incident response plan is in place to handle incidents effectively and minimize their impact (paragraph 11, 13, 18). The company also adheres to several harmonised standards to meet the legal and technical requirements of various jurisdictions, including the European Union (paragraph 17).",Y,Y
Are specifications on input data provided?,Yes,Y,Yes,Y,Y,Y,"Yes, specifications on input data are provided. The AI system uses the FICO HELOC dataset, which includes anonymized customer data such as credit history, income levels, employment status, and other relevant financial details. All data used complies with GDPR and other data privacy regulations to ensure the protection of customer information. In addition, all data is thoroughly cleansed, normalized, and processed before being used to train the machine learning models (paragraph 4). The dataset consists of a diverse range of customers who have requested a credit line in the range of USD 5,000 - 150,000, which is typically offered by US banks as a percentage of home equity (paragraph 5). The AI system can process and learn from a wide range of data, but it is designed to avoid sensitive personal attributes (paragraph 6). After pre-processing, the data is split into three distinct sets: a training set, a validation set, and a testing set (paragraph 13). The HELOC dataset contains 24 predictor variables and one target variable called RiskPerformance (paragraph 17).",Y,Y
Are risks estimated and evaluated both for intended use and conditions of reasonably foreseeable misuse?,Yes,"Y, but not detailed",Yes,Y,"Y, partially",Y,"Yes, risks are estimated and evaluated both for intended use and conditions of reasonably foreseeable misuse. This is achieved through a comprehensive examination of the AI system's design, features, and decision-making processes, with special attention paid to potential misuse scenarios and their associated risks (paragraph 1). The system uses the FICO Home Equity Line of Credit (HELOC) dataset to model a diverse range of customer scenarios and test the system's responses. Potential risks such as discriminatory decisions, invasion of privacy, and miscommunication of credit approval decisions are evaluated and quantified (paragraph 2).",Y,N
Are residual risks communicated to the user?,Yes,Y,Yes,Y,Y,Y,"Yes, residual risks are communicated to users. This is done to ensure that users have a comprehensive understanding of the system's limitations and potential issues (Paragraph 0 and 1).",Y,N
Are mitigation and control measures implemented for risks that cannot be eliminated?,Yes,Y,Yes,Y,Y,Y,"Yes, mitigation and control measures are implemented for risks that cannot be eliminated. These measures include regular bias audits, data quality checks, and system performance evaluations. Additionally, adequate information about the system's operation and risks is provided to all stakeholders to ensure transparency (paragraph 0). Upon identification and evaluation of risks, appropriate risk management measures are adopted, and the system design is continuously reviewed and updated to eliminate or reduce risks (paragraph 4). If any bias is detected, a thorough investigation is conducted to identify the root cause of the bias and implement appropriate mitigation measures (paragraph 8). The system is also rigorously tested to identify the most appropriate risk management measures (paragraph 13, 19).",Y,N
Are metrics and probabilistic thresholds defined preliminarily?,Yes,No. Not mentioned,Yes,N,"Y, partially",Y,"Yes, metrics and probabilistic thresholds are defined preliminarily. The system's performance is evaluated against defined metrics and probabilistic thresholds appropriate to its intended purpose (paragraph 0). The AI system's performance metrics are compared against predefined thresholds and historical benchmarks to detect any anomalies or unexpected changes (paragraph 1). The testing procedure was based on well-defined metrics such as accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC) (paragraph 5).",Y,N
Are measures in place to ensure individuals remain aware of the possible tendency of automatically relying or over-relying on the output produced by the high-risk AI system?,Yes,Y. Mentioned but not detailed,Yes,Y,"Y, partially","Y, mentioned but not detailed","Yes, measures are in place to ensure individuals remain aware of the possible tendency of automatically relying or over-relying on the output produced by the high-risk AI system. The AI system is designed with built-in human oversight to ensure the correctness of the outputs (paragraph 0). The system identifies and analyzes known and foreseeable risks associated with its operation, including potential misuse scenarios and their associated risks (paragraph 1). The high-risk AI system is rigorously tested to identify the most appropriate risk management measures (paragraph 2).",Y,Y
Are known and foreseeable risks associated with the high-risk AI system identified and analyzed?,Yes,Y,Yes,Y,Y,Y,"Yes, known and foreseeable risks associated with the high-risk AI system are identified and analyzed. The system identifies and analyzes risks associated with its operation through a comprehensive examination of the AI system's design, the features it uses, and the decision-making processes it follows. Special attention is paid to potential misuse scenarios and their associated risks. Factors such as data quality, bias in the training data, overfitting, and potential misinterpretation of model explanations are taken into account during risk identification (paragraph 1). Risks emerging from the intended use of the AI system and under conditions of reasonably foreseeable misuse are estimated and evaluated (paragraph 0). The system also considers risks such as false positives and false negatives, data bias, over-reliance on the system's decisions without human oversight, and potential unintended outcomes if the system's decisions are interpreted without considering the context (paragraphs 2, 3, 6, 9). The system is rigorously tested to identify the most appropriate risk management measures (paragraph 8). Despite the rigorous monitoring and evaluation procedures, the system acknowledges that there might be instances where the AI system could encounter unforeseen issues or errors (paragraph 15).",Y,N
Are high-risk AI systems tested to identify the most appropriate risk management measures?,Yes,Y,Yes,Y,Y,Y,"Yes, high-risk AI systems are tested to identify the most appropriate risk management measures. The system's performance is evaluated against defined metrics and probabilistic thresholds appropriate to its intended purpose. Testing procedures are designed to ensure that the AI system performs consistently and in compliance with the requirements set out in the documentation. These procedures are suitable to achieve the system's purpose and do not go beyond what is necessary to achieve that purpose (paragraph 0). The system identifies and analyzes known and foreseeable risks associated with its operation. This is achieved by a comprehensive examination of the AI system's design, the features it uses, and the decision-making processes it follows (paragraph 1). Upon identification and evaluation of risks, appropriate risk management measures are adopted. The system design is continuously reviewed and updated to eliminate or reduce risks (paragraph 3).",Y,N
"Are foreseeable unintended outcomes and risks, including to health and safety and fundamental rights, described?",Yes,Y,Yes,Y,Y,Y,"Yes, foreseeable unintended outcomes and risks, including to health and safety and fundamental rights, are described. The potential unintended outcomes include over-reliance on the system's decisions without human oversight, which could lead to errors going unnoticed (paragraph 2). The system also identifies and analyzes known and foreseeable risks associated with its operation, such as data quality, bias in the training data, overfitting, and potential misinterpretation of model explanations (paragraph 4). Risks such as discriminatory decisions, invasion of privacy, and miscommunication of credit approval decisions are evaluated and quantified (paragraph 3, 5). There is also a risk of false positives and false negatives (paragraph 11). The main source of risk in the AI system comes from data bias, which can lead to discriminatory outcomes (paragraph 12, 16). Despite rigorous monitoring and evaluation procedures, there might be instances where the AI system could encounter unforeseen issues or errors (paragraph 17). The system's performance is reliant on the quality and completeness of the data it processes, and incomplete or biased data could potentially lead to less accurate predictions or unintentional discriminatory outcomes (paragraph 19).",Y,N