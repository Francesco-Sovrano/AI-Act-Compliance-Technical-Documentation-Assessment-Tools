# Checklist to verify the presence of the various elements outlined in the ANNEX IV for technical documentation

This checklist can serve as a comprehensive guide to ensure that the technical documentation contains all the required elements as outlined in ANNEX IV of the EU Artificial Intelligence Act.

### General Description of the AI System
1. **Intended Purpose and Developers**
   - Does the documentation include a general description stating the intended purpose of the AI system?
   - Are the persons or teams responsible for developing the AI system clearly identified?
   - Is the date and version of the system provided?

2. **Interaction with Other Hardware/Software**
   - Is there information on how the AI system interacts with hardware or software that is not part of the AI system itself, where applicable?

3. **Software/Firmware Versions**
   - Are the versions of relevant software or firmware listed?
   - Are there any requirements related to version updates?

4. **Market and Service Placement**
   - Does the documentation describe all forms in which the AI system is placed on the market or put into service?

5. **Hardware Description**
   - Is the hardware on which the AI system is intended to run described?

6. **Component of Products**
   - If applicable, are there photographs or illustrations available that show the external features, marking, and internal layout of products in which the AI system is a component?

7. **Instructions for Use and Installation**
   - Are there instructions for users on how to use the AI system?
   - Where applicable, are installation instructions provided?

### Detailed Description of Elements and Development Process
8. **Development Methods**
   - Does the documentation describe the methods and steps performed for the development of the AI system?

9. **Design Specifications**
   - Are there sections detailing the use of any pre-trained systems or third-party tools?
   - Are the design specifications, including the general logic and algorithms, clearly outlined?
   - *Are trade-offs in the technical solutions, such as accuracy vs. speed or privacy vs. functionality, clearly documented?*

10. **System Architecture**
    - Is the system architecture, including software component interactions, explained?
    - Is there information about the computational resources used in different phases like development, training, testing, and validation?

11. **Data Requirements**
    - Are the data requirements including datasheets, training methodologies, and data sets described?

12. **Human Oversight Measures**
    - Is there an assessment of human oversight measures as per Article 14?
    - Does the technical documentation indicate that the high-risk AI system is designed and developed to be effectively overseen by natural persons?
    - Does the documentation specify how human oversight aims to prevent or minimize risks to health, safety, or fundamental rights?
    - Are the measures for human oversight identified and built into the high-risk AI system by the provider, or are they identified as appropriate to be implemented by the user?
    - Are these measures designed to enable individuals to understand the capacities and limitations of the AI system?
    - Do the human oversight measures help individuals detect and address signs of anomalies, dysfunctions, and unexpected performance as soon as possible?
    - Are measures in place to ensure individuals remain aware of the possible tendency of automatically relying or over-relying on the output produced by the high-risk AI system?
    - Do the measures enable individuals to correctly interpret the high-risk AI systemâ€™s output?
    - Can individuals decide not to use the high-risk AI system, or otherwise disregard, override, or reverse the output of the AI system?
    - Is there a provision for individuals to intervene on the operation of the high-risk AI system or to interrupt the system, such as through a "stop" button or a similar procedure?
    - For systems identified in point 1(a) of Annex III, does the human oversight measure ensure that no action or decision is taken based on the AI system's identification unless verified and confirmed by at least two natural persons?

13. **Pre-determined Changes**
    - Does the documentation describe any pre-determined changes to the system and its performance?

14. **Validation and Testing**
    - Are validation and testing procedures clearly defined, along with used metrics and test logs?

### Monitoring, Functioning, and Control
15. **Capabilities and Limitations**
    - Does the documentation detail the capabilities and limitations of the AI system?

16. **Unintended Outcomes and Risks**
    - Is there information on the degrees of accuracy for specific target groups?
    - Are foreseeable unintended outcomes and risks, including to health and safety and fundamental rights, described?

17. **Human Oversight Measures**
    - Are technical measures for human oversight outlined?

18. **Input Data Specifications**
    - Are specifications on input data provided?

### Risk Management System, in Accordance with Article 9

19. **Establishment of Risk Management System**
   - Is there evidence that a risk management system has been established, implemented, documented, and maintained for high-risk AI systems?
  
20. **Lifecycle and Iterative Process**
   - Does the documentation indicate that the risk management system is a continuous iterative process run throughout the entire lifecycle of the high-risk AI system?
   - Is there a provision for regular systematic updates?

21. **Identification and Analysis of Risks**
   - Are known and foreseeable risks associated with the high-risk AI system identified and analyzed?

22. **Risk Estimation and Evaluation**
   - Are risks estimated and evaluated both for intended use and conditions of reasonably foreseeable misuse?

23. **Post-market Monitoring Data**
   - Does the risk management system include evaluation of risks based on data gathered from post-market monitoring?

24. **Risk Management Measures**
   - Are suitable risk management measures adopted?
   - Do the risk management measures consider the effects and possible interactions resulting from combined application requirements?
   - Do the risk management measures reflect the generally acknowledged state of the art?

25. **Residual Risks**
   - Is there a judgment on the acceptability of any residual risks?
   - Are residual risks communicated to the user?

26. **Design and Development for Risk Reduction**
   - Does the documentation show evidence of elimination or reduction of risks through adequate design and development?

27. **Mitigation and Control Measures**
   - Are mitigation and control measures implemented for risks that cannot be eliminated?

28. **Information and Training**
    - Is there provision for adequate information pursuant to Article 13, especially regarding risks?
    - Where appropriate, is training provided to users?

29. **User Considerations**
    - Is due consideration given to the technical knowledge, experience, education, and training expected from the user and the environment where the system will be used?

30. **Testing for Risk Management**
    - Are high-risk AI systems tested to identify the most appropriate risk management measures?
    - Do testing procedures ensure consistent performance and compliance?

31. **Testing Procedures and Metrics**
    - Are testing procedures suitable for the intended purpose?
    - Are testing procedures performed at appropriate times, including before market placement?
    - Are metrics and probabilistic thresholds defined preliminarily?

32. **Child Impact**
    - Is specific consideration given to whether the high-risk AI system is likely to be accessed by or impact children?

33. **Credit Institutions Compliance**
    - If the AI system is for credit institutions regulated by Directive 2013/36/EU, does it adhere to the risk management procedures pursuant to Article 74 of that Directive?

### Changes Through Lifecycle
34. **Lifecycle Changes**
    - Does the documentation describe any changes made to the system throughout its lifecycle?

### Standards and Compliance
35. **Harmonised Standards**
    - Is there a list of applied harmonized standards?
    - If no harmonized standards are applied, is there a description of the solutions adopted to meet the requirements?

### EU Declaration of Conformity
36. **EU Declaration of Conformity**
    - Is a copy of the EU declaration of conformity included in the documentation?

### Post-Market Performance Evaluation
37. **Post-market Monitoring**
    - Is there a detailed description of the system to evaluate the AI system's performance in the post-market phase?
    - Does the description of the system to evaluate the AI system's performance include a post-market monitoring plan as referred to in Article 61(3)?
