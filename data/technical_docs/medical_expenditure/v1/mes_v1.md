# 1. AI-Powered Medical Expenditure System: Comprehensive Technical Documentation

This technical documentation provides a comprehensive overview of the AI-based Medical Expenditure System developed by our company. The system's primary objective is to predict the annual healthcare expenditure of individuals based on demographic and socio-economic variables, as well as self-reported medical conditions. It caters to healthcare "payers" such as insurance companies, employers, governments, or individuals who bear the financial responsibility for these costs.

Our AI system adheres to strict guidelines, ensuring transparency, fairness, and robustness. It also emphasizes explainability to meet the needs of both internal teams and external stakeholders.

The Medical Expenditure System serves multiple user groups, including healthcare data scientists, insurance underwriters, and legal experts. Each group has distinct requirements, and the system provides tailored explanation methods for machine learning predictions.

For healthcare data scientists, the system offers interpretable models that facilitate comprehensive model evaluation. These models include directly interpretable forms, allowing for a holistic understanding of the model's behavior. They not only identify the most predictive features but also reveal the nature of the dependencies, such as their direction and shape. These insights can be cross-referenced with domain knowledge from healthcare experts or reviewed by managers, bolstering confidence in the system's expected performance. Furthermore, the insights can inform interventions to mitigate costs, contributing to effective care management. Although these models are not causal, they can be interpreted causally with the assistance of expert knowledge or suggest causal hypotheses for future studies.

Insurance underwriters play a vital role in making final decisions based on the system's predictions. To facilitate their understanding of machine learning outputs, we employ the ProtoDash method (class ProtodashExplainer). This method identifies prototypes or representatives in the training data that are similar to a given individual and receive the same class label. By showcasing examples, we enhance the explainability of the system for insurance underwriters.

Legal experts, such as attorneys or compliance officers, require explanations for the recommendations generated by the system. These explanations are crucial for ensuring legal compliance and ethical considerations. The system utilizes the Contrastive Explanations Method (CEM), which highlights features present in the input instance that influence the model's classification. Additionally, CEM identifies features that are minimally absent but would have altered the classification if present. This level of transparency enables legal experts to understand the reasons behind the system's recommendations and assess their compliance with applicable laws and regulations.

The Medical Expenditure System leverages the power of the XGBoost machine learning algorithm, known for its robustness and accuracy. The XGBoost algorithm has been extensively trained on healthcare data to provide reliable predictions and insights.

Our Medical Expenditure System is integrated into a larger Care Management System, offering various services. It allows for prioritization of cases and provides insights to authorized members of the medical staff through the "Medical Staff" interface.

The system is developed on the IBM AIX360 platform and utilizes the released version aix360 v0.2.1. It relies on a range of dependencies, including 'joblib', 'scikit-learn', 'torch', 'tensorflow', 'keras', 'matplotlib', 'numpy', 'pandas', 'scipy', 'xgboost', and others. The model has undergone extensive training to ensure optimal performance.

To deploy the AI-based Medical Expenditure System, the following system requirements should be met:

- Operating System: Compatibility with Windows, Linux, and macOS.
- Processor: Minimum requirement of an Intel Core i5 processor.
- RAM: At least 8 GB for optimal performance.
- Storage: Minimum of 100 GB of free disk space.
- Graphics Card: A dedicated Nvidia graphics card.
- Internet Connection: Stable connection for seamless API access.
- Additional Software

The following sections detail the specifics of the AI-based Credit Approval System:

1. **Data Source, Pre-processing, and Training**
2. **Explainability Features**
3. **Lifecycle for Evaluating AI System Performance in the Post-Market Phase**
4. **Post-Market Monitoring Plan**

Each section includes a detailed account of our procedures, methodologies, and commitments, providing clear insights into our AI system's operations. By the end of this document, readers should have a thorough understanding of how our Credit Approval AI System functions, how it meets the EU AI Act's requirements, and how we plan to maintain and improve its performance post-deployment. 

Let's dive into the specifics of our AI system, beginning with our data source and how we preprocess and train our models.

# 2. Detailed Description of the AI System's Elements and Development Process

## Data Source, Pre-processing, and Training for Medical Expenditure Prediction

In this section, we provide details about the data source, pre-processing techniques, and training methodologies used in the development of our AI system for medical expenditure prediction. We emphasize the importance of privacy regulations and ethical guidelines in all stages of the process.

### Data Source

The medical expenditure prediction system utilizes a dataset containing anonymized patient data, including health status, demographics, and other relevant factors. The data collection process strictly adheres to privacy laws and regulations, ensuring the protection of personally identifiable information (PII) and patient privacy.

### Data Pre-processing

Before training the AI models for medical expenditure prediction, a comprehensive pre-processing phase is undertaken to ensure data quality, fairness, and non-discrimination. The following steps are followed:

**Data Cleaning**: Inconsistencies, errors, and duplicates in the medical expenditure dataset are meticulously removed to ensure the integrity and quality of the data.

**Feature Selection**: Relevant features that contribute to medical expenditure prediction are identified using domain knowledge and feature importance techniques. This step ensures that only the most relevant features are utilized during model training.

**Data Normalization**: The data is normalized to achieve consistent scaling across all features. Normalization helps the models train effectively and avoids bias towards features with larger scales.

**Bias Detection and Alleviation**: The AI system incorporates various metrics and techniques to detect and mitigate biases in the dataset. Metrics such as disparate impact, average odds difference, statistical parity difference, equal opportunity difference, and Theil index are employed to quantify biases. Techniques like reweighing, prejudice remover, and disparate impact remover are used to reduce bias and ensure fairness in the model.

The **reweighing algorithm** is specifically applied during the pre-processing stage to transform the training dataset and mitigate bias. It adjusts the training data based on the probability of favorable outcomes for different groups, aiming to prevent bias in the model's predictions. After the transformation, the model is re-evaluated to ensure fairness and unbiased decision-making.

### Data Splitting

After pre-processing, the data is split into three distinct sets: a training set, a validation set, and a testing set. This partitioning enables us to train our models effectively and evaluate their performance objectively:

1. **Training Set:** The majority of the data (around 70%) is used to train our models.
2. **Validation Set:** A portion of the data (around 15%) is set aside to tune the model's parameters and prevent overfitting.
3. **Testing Set:** The remaining data (approximately 15%) is used to test the model's performance on unseen data, which gives us a realistic measure of how the model will perform in real-world scenarios.

The model's performance is evaluated using the testing set, which gives us a realistic measure of how the model will perform in real-world scenarios. The model is regularly monitored and updated to detect and address emerging biases promptly. This monitoring process also enables the system to adapt to changing trends and operate in compliance with the EU AI Act.

### Model Training

The training phase involves fitting our models to the training dataset. The primary predictive model used in our AI system is XGBoost, a gradient boosting framework renowned for its efficiency and performance. XGBoost works by iteratively combining multiple decision trees to create a strong learner that can predict medical expenditure for individuals. It employs a novel technique called gradient boosting to improve the performance of decision trees by combining their predictions.

We train the XGBoost model using the training set, tuning its hyperparameters using the validation set to avoid overfitting and underfitting. The model's performance is evaluated using the subset accuracy metric, as calculated by the sklearn.metrics.accuracy_score function. The XGBoost model has several benefits that make it ideal for our medical expenditure system. It's capable of handling a large number of features, is robust to outliers in the data, and can model complex non-linear relationships. Furthermore, it provides several parameters that can be tuned to optimize the model's performance.

In addition to its efficiency and performance, XGBoost is also considered state-of-the-art for tabular data (such as the Medical Expenditure System data). It has consistently outperformed other popular machine learning algorithms in various data science competitions and real-world applications. XGBoost's ability to handle large datasets with many features and its flexibility to incorporate a variety of objective functions and evaluation metrics make it a popular choice for many high-risk AI-based systems, including our medical expenditure system.

The XGBoost model is trained on the pre-processed and normalized data, with its performance evaluated using subset accuracy, as calculated by the sklearn.metrics.accuracy_score function. Our model is trained to minimize the risk of false negatives (i.e., underestimating medical expenditure for individuals) while balancing the risk of false positives (i.e., overestimating medical expenditure for individuals). This approach ensures that our model is more accurate in predicting medical expenditure.

### Explainability Features
A key feature of our AI system is its explainability. We believe it's essential for data scientists, medical staff, and patients to understand the reasoning behind the medical expenditure approval decisions made by the system. The system incorporates built-in human oversight to ensure that the outputs are correct. The models are designed to be transparent, so their workings can be easily understood. They are also monitored during deployment, and adjustments can be made as necessary.

#### Linear Rule Regression (LinRR)
LinRR is a variant of Generalized Linear Rule Models (GLRM) specifically designed for predicting real-valued outcomes. It produces weighted combinations of AND rules, which provide both accuracy and interpretability. The training process for LinRR involves the following steps:

- **Model Initialization**: The LinRR algorithm is initialized with default parameters and an initial set of rules.
- **Training Dataset**: The pre-processed and normalized dataset is divided into a training set and a validation set. The training set is used to train the LinRR model.
- **Rule Generation**: LinRR generates a set of candidate rules based on the training set. Each rule consists of a conjunction of conditions over the input features.
- **Rule Weighting**: LinRR assigns weights to each rule based on their importance in predicting the target variable. This is done by solving an optimization problem that aims to maximize the model's predictive performance while penalizing complex rules.
- **Model Fitting**: LinRR fits the weighted rules to the training dataset using a linear regression algorithm. It learns the coefficients for each rule, which determines the contribution of each rule to the final prediction.
- **Model Evaluation**: The fitted LinRR model is evaluated on the validation set to assess its predictive performance. Various evaluation metrics such as mean squared error (MSE), mean absolute error (MAE), and R-squared are calculated to measure the model's accuracy.
- **Rule Refinement**: If the LinRR model's performance is unsatisfactory, the rule generation and weighting steps are repeated with different parameters to generate a new set of rules. This iterative process continues until a satisfactory model is obtained.
- **Final Model Selection**: The LinRR model with the best performance on the validation set is selected as the final trained model for predicting medical expenditure.

#### Boolean Rule Column Generation (BRCG)
BRCG is a rule-based algorithm used for predicting binary outcomes. It generates rules in the form of AND combinations of conditions, similar to LinRR. The training process for BRCG involves the following steps:

- **Model Initialization**: The BRCG algorithm is initialized with default parameters and an initial set of rules.

- **Training Dataset**: The pre-processed and normalized dataset is divided into a training set and a validation set. The training set is used to train the BRCG model.

- **Rule Generation**: BRCG generates a set of candidate rules based on the training set. Each rule consists of a conjunction of conditions over the input features.

- **Rule Selection**: BRCG selects a subset of the candidate rules that maximize the model's predictive performance on the training set. This is done by solving an optimization problem that balances accuracy and complexity.

- **Model Fitting**: BRCG fits the selected rules to the training dataset using a classification algorithm. It learns the parameters for each rule, which determines the contribution of each rule to the final prediction.

- **Model Evaluation**: The fitted BRCG model is evaluated on the validation set to assess its predictive performance. Evaluation metrics such as accuracy, precision, recall, and F1 score are calculated to measure the model's effectiveness.

- **Rule Refinement**: If the BRCG model's performance is unsatisfactory, the rule generation and selection steps are repeated with different parameters to generate a new set of rules. This iterative process continues until a satisfactory model is obtained.

- **Final Model Selection**: The BRCG model with the best performance on the validation set is selected as the final trained model for predicting binary outcomes related to medical expenditure, such as whether a patient will require a specific medical procedure or not.

Once both the LinRR and BRCG models have been trained and validated, they can be used to make predictions on new, unseen data. The models utilize the generated rules and their respective weights or parameters to provide accurate predictions for medical expenditure and binary outcomes related to healthcare.

# 3. Detailed Information about the Monitoring, Functioning, and Control of the AI System
No information available via notebooks

# 4. Detailed Description of the Risk Management System
No information available via notebooks

# 5. Lifecycle for Evaluating AI System Performance in the Post-Market Phase

The AI-based Medical Expenditure System is designed to continually learn and improve from the new data it encounters post-deployment. To ensure that the system maintains its performance and complies with regulatory requirements, a lifecycle has been established to evaluate its performance in the post-market phase.

The lifecycle comprises three stages: monitoring, testing, and reporting.

**Monitoring**. During the monitoring phase, we gather data on the system's real-world performance. This includes system inputs and outputs, user feedback, and any errors or anomalies that might occur.

**Testing**. In the testing phase, the AI system is subjected to various scenarios to assess its robustness, accuracy, and performance. This includes testing the system with new, unseen data to ensure it can generalize well beyond the initial training set.

**Reporting**. The reporting phase involves generating comprehensive reports on the system's performance, including any issues identified during monitoring and testing, as well as any corrective actions taken. These reports are then submitted to the relevant regulatory authorities, ensuring we maintain full transparency and compliance with regulatory requirements.

The evaluation of the AI system's post-market performance is guided by industry standards for software quality measurement and information security management. Adherence to these standards ensures the system maintains regulatory compliance and delivers reliable performance.

# 6. List of the Harmonised Standards Applied 
No information available via notebooks

# 7. EU declaration of conformity
No information available via notebooks

# 8. Post-Market Monitoring Plan

Ensuring the ongoing performance and compliance of our AI-based Medical Expenditure System post-deployment requires a robust post-market monitoring plan. This plan comprises several components, which are designed to collect and analyze performance data, assess the system's ongoing performance, and facilitate reporting and documentation.

### Data Collection

Data collection is a continuous process that captures the system's inputs and outputs, user feedback, error reports, and other relevant data. This real-world data is invaluable for understanding the system's performance in various scenarios and identifying areas for improvement.

### Data Analysis

Once collected, the data is systematically analyzed to identify any potential issues, such as declining performance, bias in decision-making, or security vulnerabilities. By observing trends and patterns in the data, we can proactively address potential issues before they impact the system's performance.

### Regular Testing

The system is regularly tested using the newly collected data. These tests assess the system's accuracy, fairness, robustness, and security. If there are significant changes in the healthcare landscape or regulatory requirements, additional tests are conducted to ensure the system's performance remains consistent.

### Incident Response

In the event of any significant issues or incidents, a response plan is activated. This plan includes immediate measures to mitigate any harmful effects, an investigation into the cause of the incident, and long-term measures to prevent similar incidents in the future.

### Reporting and Documentation

Regular reports are generated detailing the system's performance, any identified issues or incidents, and any corrective actions taken. These reports are shared with relevant regulatory bodies as required. All activities related to post-market monitoring are thoroughly documented, creating a comprehensive record of the system's performance and compliance with regulations.

### Updates and Maintenance

Based on the findings from data analysis and regular testing, the AI system will be periodically updated and maintained. These updates might include changes to the machine learning model, the data processing methods, or the user interface.

### Stakeholder Feedback

Feedback from all stakeholders, including end-users, is continuously collected and considered when making improvements to the system. This feedback provides valuable insights into the system's performance from different perspectives.

By implementing this post-market monitoring plan, we aim to ensure that our AI-based medical expenditure system continues to deliver reliable performance and meets the high standards set by regulatory authorities. We believe that through constant monitoring, testing, and improvement, we can provide a system that is not only effective but also trustworthy and transparent. Our goal is to incorporate stakeholder feedback to enhance the accuracy and usability of the system, ultimately improving the prediction of medical expenditure for individuals and meeting the needs of our users.